Hub songs are found by user/title/artist/album.  Local songs are
found by file path.  It is possible to have more than one local song map
to the same hub song (multiple copies of equivalent songs locally).  It is
also possible to have a local song map to a different hub song than it's
previous mapping (changed title/artist/album metadata).

Each song returned from hubsync is found locally via pdat.tiarabLookup which
may find several matching local results, all of which are updated.

The hub's responsibility is to preserve song ratings, providing sync and
collaborative sharing support.  Until a song is rated, there is no reason to
send it to the hub, or save it on the hub, since there is nothing helpful to
preserve.  To preserve the latest info, the hub will avoid updating a song
if the lp timestamp given is older than the lp value it already has.

The app's responsibility is to send song ratings that should be preserved
across devices and made available for collaboration.  It does this solely by
tracking Song.lp values relative to when the app last communicated with the
hub.  The app saves, sends, and downloads song.dsId, but this is solely for
general reference and is not used for matching.  Songs sent to the hub
might have had their metadata changed and now ti/ar/ab map to a different
dsId.  Updated songs received from the hub may map to multiple copies of the
same song on the local device.  The dsId is just for general reference.


Notes on PCRE limits:
--------------------

To detect and mitigate DOS attacks, the web server is constantly monitoring
any requests that cause the server to do too much work.  When the server
sees a request that resulted in an unreasonably heavy load, it makes a note
of the request and uses Perl Compatible Regular Expressions (PCRE) to try
and avoid allowing anything similar through anytime soon.  If the server
runs into more of these suspicious requests than whatever maximum it is
configured to check, it logs "Execution error - PCRE limits exceeded".

The server is always monitoring, and may take evasive action through request
slowdowns and eventual bitbucket relegation even without logging an error.
It is critical that repeated requests be as efficient and unique as possible
to smurf past the (rightfully) highly suspicious web server monitoring.  The
hubsync processing in particular needs
  - user specific API sync endpoints to scale service per individual
  - sync continuation tokens to avoid sending full auth every time
  - minimized data (quantity and quality)


Initial data restore:
--------------------

Installing Digger on a new device and signing in to DiggerHub requires
downloading your hub ratings to restore your local data for use.  This is a
heavyweight operation as you may have thousands of song ratings, and while
you might not need all your ratings for a particular installation, telling
the hub which ones you need and then only downloading those would take more
hub work.  Repeated long calls back and forth to the server are bad.

To optimize app startup sync, the app first restores from hub backup.  On
any day a user has communicated with the hub, that night the hub writes a
backup file with the song data for that user, placing the name of that file
and a user-specific custom api url for access into DigAcc.settings.backup.

When you first sign in from the app on a new platform, the app fetches your
backup information via the custom url.  Unlike other API calls, the data is
not returned in JSON format because it's too big to send that way.  By
reducing the returned song data to a CSV of the essential field values, the
returned data is typically just over 5 times smaller.  This could be reduced
further by zip compression in the future as needed.

top.asu.signinProc->srs.noteDataRestorationNeeded turns off other sync
processing, then calls srs.restoreFromBackup to fetch the backup data and
restore the app.  In addition to restoring data for each song, restore also
recalculates app.pdat.dbObj().lastSyncPlayback from the latest lp value of
the songs it has restored.

app.pdat.dbObj().lastSyncPlayback holds the most recent song.lp value
received from the hub.


hubsync processing:
------------------

When a song is played, its "lp" (last played) timestamp is updated locally.
There is no hub interaction during local save of the song data, but hubync
gets scheduled and runs some seconds later.  It is possible to be using the
Digger app on multiple devices, possibly with interleaved hubsync calls.
To maintain user data consistency, each app instance must
  1. Download and merge any hub songs changed since last sync.
  2. Upload app songs changed since last sync and save returned hub data.

If you listen to overlapping song collections on two different devices, it
can happen that you play a song on one device, then have it play again on
the other device before hubsync merge updates get processed.  The correct
merge processing is to update the currently playing song with the hub data.
If you made changes to the song prior to hubsync, those changes will get
overwritten by the hub data.  Usually this is intuitive, and it can be
welcome to see the latest saved rating info kick in and update the display.
On the other hand if you started to adjust the rating only to have it revert
as the hubsync merge happens this might be surprising.  Hopefully the merge
is welcome in either case.  Since the whole point of hubsync is to
distribute data across app instances, the pulled hub song data always
takes precedence over outdated app song data.

If listening to overlapping song collection on two different devices that
have both been out of hubsync contact for a while, then it is likely the
second device will have several songs merged down from the hub.  The app
keeps track of lastSyncPlayback as it synchronizes hub data.

App-Hub comms:
  - Comms data object: {syncdata:[], <authparam(s)>}
    - syncdata: JSON.stringify([strHubSyncDirective, strSong1, strSong2...])
      The songs are csv serialized.  The Hub Sync Directive (hsd) is JSON
      serialized so the array elements are all the same type (python).
  - A new Hub Sync Communications Token (hsct) is returned with each call.
    If an invalid hsct is used for a call, the server returns an
    authentication error similar to if the wrong password was used.
  - hsd and auth for calls:
    -> {action:"start"} (email/token auth)
       <- [{action:"started", hsct:"abc123"}]
    -> {action:"pull", syncts:lastSyncPlayback} (hsct auth)
       <- [{action:"merge", hsct:"def456", provdat:pv}, songs...]
          pv: "complete" or "partial".  If "partial" there are more updated
              songs to download and restoring from backup might be preferable.
    -> {action:"upload"} [songs] (hsct auth)
       <- [{action:"received", hsct:"ghi789"}, songs...]

Only one Digger app instance per user can be in hubsync communication at a
time, which is enforced viat the hsct.  A different app instance for the
same user will need to restart its pull/upload sequence and take over hsct
authentication.  This avoids common race condition errors such as:
  - Overwrite of interim rating data.  Example sequence:
      - user updates SongA on DeviceP
      - user updates SongB on DeviceQ
      - user updates SongB on DeviceP without having pulled updates
    In this case any changes made to SongB on DeviceQ will be overwritten by
    SongB data from DeviceP.  The server might conceivably require and check
    song.modified to reject the second SongB update from DeviceP, but with
    ti/ar/ab<->dsId mappings and dupe song tracking this gets complex.  With
    more than one song typically being uploaded, checking each song would
    increase server load and hubsync communications load, then require
    reupload of the same songs again due to what was typically just the lp
    value having changed.  The server is not responsible for this work.
  - Starvation of rating data.  Example sequence:
      - user updates SongA on DeviceP adding rating info and comment
      - user updates SongB on DeviceQ without having pulled first
    In this case SongA on DeviceQ will remain outdated until
      1. SongA is updated again on DeviceQ (overwrite)
      2. DeviceQ data is restored from backup, including updated SongA
    Before overwrite or restore, whenever the user is filtering or searching
    for songs on DeviceQ, they won't find what they possibly remember having
    modified for SongA.  Their data may be safe on the hub, but they are not
    seeing that and could overwrite their data.  App data responsibility.


encoding and transmission:
-------------------------

Sending an array of songs as JSON includes repeated song field names for
each field value.  That's inefficient, and it invites web server security
scrutiny, so songs are converted to CSV with only the necessary song data
field values required for update (see top.srs.song2csv).

Overview of transmit/receive process:
  - abbreviated "song" object with just rating value and ugly note text:
        {rv:8, nt:"\"',`f(select)&"}
  - song object after web server data security blocking appeased:
        {rv:8, nt:"\"ESCSINGLEQUOTE,`fESCOPENPARENWSRWtcelesESCCLOSEPARENESCAMPERSAND"}
  - song CSV string:
        "8,\"%22ESCSINGLEQUOTE%2C%60fESCOPENPARENWSRWtcelesESCCLOSEPARENESCAMPERSAND\""
  - abbreviated syncdata to send
        [{action:"upload"}, "8,\"%22ESCSINGLEQUOTE%2C%60fESCOPENPARENWSRWtcelesESCCLOSEPARENESCAMPERSAND\""]
  - hubsync call object with JSON stringified syncdata value:
        {syncdata:"[{\"action\":\"upload\"},\"8,\\\"%22ESCSINGLEQUOTE%2C%60fESCOPENPARENWSRWtcelesESCCLOSEPARENESCAMPERSAND\\\"\"]", hsct:"whatever"}
  - hubsync call POST data
        "syncdata=%5B%7B%22action%22%3A%22upload%22%7D%2C%228%2C%5C%22%2522ESCSINGLEQUOTE%252C%2560fESCOPENPARENWSRWtcelesESCCLOSEPARENESCAMPERSAND%5C%22%22%5D&hsct=whatever"
  - hub received syncdat parameter:
        "[{\"action\":\"upload\"},\"8,\\\"%22ESCSINGLEQUOTE%2C%60fESCOPENPARENWSRWtcelesESCCLOSEPARENESCAMPERSAND\\\"\"]"
  - python json.loads syncdat list:
        [{"action": "upload"}, "8,\"%22ESCSINGLEQUOTE%2C%60fESCOPENPARENWSRWtcelesESCCLOSEPARENESCAMPERSAND\""]
  - song dict from csv conversion of first list element
        {"rv":8, "nt":"\"ESCSINGLEQUOTE,`fESCOPENPARENWSRWtcelesESCCLOSEPARENESCAMPERSAND"}
  - song dict after reversing web server data security escaping:
        {"rv":8, "nt":"\"',`f(select)&"}

In actual use there are obviously more song fields and less dense
concentrations of potentially problematic characters/words.


general considerations:
----------------------

The app should not send unrated songs since there is no information to save
or communicate via the hub.  The hubsync processing skips saving unrated
songs and does not return them.

The app may update the lp for dupe songs.  How and when this is done may
vary with the platform implementation or settings.  The hub does not get
involved with dupe tracking logic.  If the app sends the same tiarab matched
song N times, it will get back N revisions of that song instance.

In the event of a "catastrophic" out of sync situation (resurrecting an
older device that has not been used for a long time) it is better to restore
from backup.  In the event of a "partial" merge response to a "pull" action,
the app will require signing in again to force a backup data restore.

The hub data "modified" value reflects when a song instance was last written
to the database.  It has a revision number after the ISO timestamp.  The
local "lp" value does not have a revision number, and may have additional
timestamp precision.  It is ok to compare the two strings directly as both
are UTC times and accurate enough for sync purposes.


Local app Song.lp timestamp updates:
-----------------------------------

The Digger UI requires song.lp be updated when a song is played, even if the
UI itself is backgrounded.  When the UI is re-foregrounded, its state needs
to be recovered and verified to avoid referencing stale data.  This local
data consistency checking and processing is the level below hubsync.

dbo.lastSyncPlayback is used for hubsync as described above.  dbo level
fields used for local consistency checking:
  - arts/awts: app read timestamp/app write timestamp 
    arts is updated by app.pdat.setDigDatAndNotify
    awts is updated by app.pdat.processNextQueuedWrite(digdat)
    - player.scm (song change manager) digDatUpdated checks awts >= mrscnts
      (most recent song change notice timestamp) to ensure it is working
      with a recently loaded digdat before changing the currently playing
      song in reaction to updated playback status.
    - deck.csa.verifyQueuedPlayback checks several seconds have elapsed
      since dbo.arts before forcing a reload due to out of sync lp.  This
      lets the app to reach a stabilized start before forcing a reload, and
      reflects the low liklihood that a fresh app start will have drifted
      out of sync with the the playback.
  - uilp: user interface last played
    uilp is set by player.playSongQueue, and may be updated by 
    deck.csa.staleDataOrInvalidPlayback to recover from lazy lp values




